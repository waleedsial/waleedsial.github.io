---
title: "Machine Learning: Linear Regression From scratch in Python Using Gradient Descent "
date: 2020-03-14
tags: [machine learning, data science, neural network, Linear Regression ]
header:
  images: "images/linear/Linear_Regression.png"
excerpt: "Machine Learning, Perceptron, Data"

---


### Developing linear regression without using any library
This blog covers following features:



- Development from scratch.
- Optimization Algorithm : Gradient Descent
- Development Language : Python
- Vectorized Implementation of gradient Descent
- Function for testing the gradient descent by checking calculated gradients


### Functions to develop


- Wrapper/Caller
- Gradient Descent
- Prediction  
- Sigmoid  
- Gradient Calculator
- Gradient Updater
- Convergence Check
- Cost Calculation
- Gradient Checker Function



# Linear Regression : What, why & How ?





```python
# One general purpose gradient descent, both regression and classification tasks use same gradient descent function.
# Algorithms are differentiated based on activation.

def gradient_descent(activation,alpha,data_matrix,theta_matrix,y_matrix,maximum_iterations,x_test_matrix,y_test_matrix,convergence_threshold):

  cost_history_array = np.zeros(maximum_iterations) # for each iteration, keep a cost for plotting
  test_cost_history = np.empty(maximum_iterations) # for saving test error

  optimum_thetas = theta_matrix
  updated_thetas = theta_matrix
  gradient_diff_sum_array = np.zeros(maximum_iterations)
  convergence_iteration_number = 0
  #convergence = False
  for i in range(maximum_iterations):

      print('Epoch : ',i)
      old_cost = cost_function(activation,data_matrix,updated_thetas,y_matrix)
      print('Cost :',old_cost)
      cost_history_array[i] = old_cost
      # Following array will save the test error for each epoch updated thetas.
      test_cost_history[i] = cost_function(activation,x_test_matrix,updated_thetas,y_test_matrix)

      gradient = gradient_calculator(activation,data_matrix,updated_thetas,y_matrix,alpha)
      # Checking, for debuggin only
      #gradient_difference = check_gradient(activation,gradient,updated_thetas,data_matrix,y_matrix)
      #gradient_diff_sum_array[i] = np.sum(gradient_difference)

      old_thetas = updated_thetas
      updated_thetas = gradient_updater(gradient,updated_thetas,alpha)

      # Calling convergence check function
      convergence = convergence_check(activation,updated_thetas,old_thetas,data_matrix,y_matrix,convergence_threshold)
      if(convergence):
          #print('convergence has occured, killing the loop')
          optimum_thetas = old_thetas
          convergence_iteration_number = i
          break


      if(i == maximum_iterations-1):
          #print('Try more Epochs for saturation, Did not converge')
          optimum_thetas = updated_thetas

      # Calling gradient checker function
      #gradient_approximation,grad_difference = gradient_checker(gradient,updated_thetas,data_matrix,y_matrix)


      #print('-------------------------------------------------------------------------------------------------------')
  return optimum_thetas,cost_history_array,gradient_diff_sum_array,test_cost_history
```
